{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data streams with Apache FlinkÂ®\n",
    "\n",
    "The goal of this additional tutorial is to showcase how data in Apache Kafka can be read and manipulated using Apache Flink.\n",
    "\n",
    "## What is Apache Flink?\n",
    "\n",
    "Apache Flink is stream processor that allows you to transmit a subset of your data based on a query.\n",
    "\n",
    "This allows you to run your normal processes and analyze your messages in real-time and output \n",
    "\n",
    "## Requirements\n",
    "\n",
    "In order to execute this tutorial you need an Aiven for Apache Flink service. Instructions for this setup are detailed in the [Workshop README](README.md).\n",
    "\n",
    "After a couple of minutes, the service will be up and running.\n",
    "\n",
    "## Create a Filtering pipeline\n",
    "\n",
    "In this section we'll create a new streaming data pipeline to filter pizza `Hawaii` from the `pizzas` topic. To create such pipeline:\n",
    "\n",
    "1. Navigate to the Aiven for Apache Kafka service page, **Topics** tab\n",
    "2. Create a new topic called `pizzaFiltered`\n",
    "3. Navigate to the Aiven for Apache Flink service page\n",
    "4. Create an integration between the Aiven for Apache Flink service and the Aiven for Apache Kafka service\n",
    "5. Navigate to the **Applications** tab\n",
    "6. Create a new Application named `filtering`\n",
    "7. Create a new version\n",
    "8. In the source table section:\n",
    "    * Select the integration with Aiven for Apache Kafka\n",
    "    * Include the following SQL\n",
    "\n",
    "      ```sql\n",
    "      CREATE TABLE pizzas(\n",
    "        id INT,\n",
    "        name STRING,\n",
    "        pizza STRING\n",
    "      )\n",
    "      WITH (\n",
    "        'connector' = 'kafka',\n",
    "        'topic' = 'pizzas',\n",
    "        'value.format' = 'json',\n",
    "        'properties.bootstrap.servers' = '',\n",
    "        'scan.startup.mode' = 'earliest-offset'\n",
    "      )\n",
    "      ```\n",
    "9. In the sink table section:\n",
    "    * Select the integration with Aiven for Apache Kafka\n",
    "    * Include the following SQL\n",
    "\n",
    "      ```sql\n",
    "      CREATE TABLE pizzas_filtered(\n",
    "        id INT,\n",
    "        name STRING,\n",
    "        pizza STRING\n",
    "      )\n",
    "      WITH (\n",
    "        'connector' = 'kafka',\n",
    "        'topic' = 'pizzaFiltered',\n",
    "        'value.format' = 'json',\n",
    "        'properties.bootstrap.servers' = '',\n",
    "        'scan.startup.mode' = 'earliest-offset'\n",
    "      )\n",
    "      ```\n",
    "10. In the transformation sql section include the following SQL\n",
    "\n",
    "    ```sql\n",
    "    INSERT INTO pizzas_filtered \n",
    "    SELECT * FROM pizzas WHERE pizza LIKE 'Hawaii%'\n",
    "    ```\n",
    "11. Click **Save and deploy later**\n",
    "12. Click **Create deployment**\n",
    "13. Click **Deploy without savepoint**\n",
    "14. Check in Aiven for Apache Kafka that the data is filled in the `pizzaFiltered` topic with only pizzas Hawaii\n",
    "\n",
    "![Consume messages from an Apache Kafka Topic](../img/hawaii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations ðŸ¥³\n",
    "\n",
    "We've ran through all of our learnings, but there is one last step. Click to [Power Down your Services to save energy and compute resources](7-power-down-services.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

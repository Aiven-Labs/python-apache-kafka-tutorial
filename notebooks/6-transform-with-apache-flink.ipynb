{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data streams with Apache Flink®\n",
    "\n",
    "The goal of this additional tutorial is to showcase how data in Apache Kafka can be read and manipulated using Apache Flink\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "\n",
    "In order to execute this tutorial you need an Aiven for Apache Flink service, in addition to the Aiven for Apache Kafka® cluster already setup. You can create one yourself or quickly get one in a couple of minutes with Aiven by:\n",
    "\n",
    "* Navigating to the [Aiven website](https://go.aiven.io/ft-signup-kafka-python) and creating an account\n",
    "* Clicking on **Create service**\n",
    "* Selecting **Apache Flink**\n",
    "* Selecting the cloud vendor and region\n",
    "* Selecting the plan (a **Business-4** plan would be enough)\n",
    "* Clicking on **Create service**\n",
    "\n",
    "After a couple of minutes, the service will be up and running.\n",
    "\n",
    "## Create a Filtering pipeline\n",
    "\n",
    "In this section we'll create a new streaming data pipeline to filter pizza `Hawaii` from the `pizzas` topic. To create such pipeline:\n",
    "\n",
    "1. Navigate to the Aiven for Apache Kafka service page, **Topics** tab\n",
    "2. Create a new topic called `pizzaFiltered`\n",
    "3. Navigate to the Aiven for Apache Flink service page\n",
    "4. Create an integration between the Aiven for Apache Flink service and the Aiven for Apache Kafka service\n",
    "5. Navigate to the **Applications** tab\n",
    "6. Create a new Application named `filtering`\n",
    "7. Create a new version\n",
    "8. In the source table section:\n",
    "    * Select the integration with Aiven for Apache Kafka\n",
    "    * Include the following SQL\n",
    "\n",
    "      ```sql\n",
    "      CREATE TABLE pizzas(\n",
    "        id INT,\n",
    "        name STRING,\n",
    "        pizza STRING\n",
    "      )\n",
    "      WITH (\n",
    "        'connector' = 'kafka',\n",
    "        'topic' = 'pizzas',\n",
    "        'value.format' = 'json',\n",
    "        'properties.bootstrap.servers' = '',\n",
    "        'scan.startup.mode' = 'earliest-offset'\n",
    "      )\n",
    "      ```\n",
    "9. In the sink table section:\n",
    "    * Select the integration with Aiven for Apache Kafka\n",
    "    * Include the following SQL\n",
    "\n",
    "      ```sql\n",
    "      CREATE TABLE pizzas_filtered(\n",
    "        id INT,\n",
    "        name STRING,\n",
    "        pizza STRING\n",
    "      )\n",
    "      WITH (\n",
    "        'connector' = 'kafka',\n",
    "        'topic' = 'pizzaFiltered',\n",
    "        'value.format' = 'json',\n",
    "        'properties.bootstrap.servers' = '',\n",
    "        'scan.startup.mode' = 'earliest-offset'\n",
    "      )\n",
    "      ```\n",
    "10. In the transformation sql section include the following SQL\n",
    "\n",
    "    ```sql\n",
    "    INSERT INTO pizzas_filtered \n",
    "    SELECT * FROM pizzas WHERE pizza LIKE 'Hawaii%'\n",
    "    ```\n",
    "11. Click **Save and deploy later**\n",
    "12. Click **Create deployment**\n",
    "13. Click **Deploy without savepoint**\n",
    "14. Check in Aiven for Apache Kafka that the data is filled in the `pizzaFiltered` topic with only pizzas Hawaii\n",
    "\n",
    "![Consume messages from an Apache Kafka Topic](../img/hawaii.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

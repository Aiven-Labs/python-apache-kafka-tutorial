{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume messages from an Apache Kafka partitioned topic\n",
    "\n",
    "In this notebook you will learn how to consume messages to an Apache Kafka topic with two partitions (created with the [dedicated notebook](3-produce-partitioned-topic.ipynb))\n",
    "\n",
    "![Consume messages from an Apache Kafka Topic](../img/consume.png)\n",
    "\n",
    "_If you haven't already created and setup your virtual environment, follow the steps from [0-setup.ipynb](0-setup.ipynb)_. You will need the `PizzasPartitioned` topic that you created in `3-producepartintioned-topic.ipynb`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create an Apache Kafka Consumer\n",
    "\n",
    "The next step is to configure the Kafka Consumer. let's recall in the previous notebook. That `Francesco's` message was sent to partition `0` and `Adele's` message was in partition `1`.\n",
    "\n",
    "```python\n",
    "producer.produce(\n",
    "    \"pizzaPartitioned\",\n",
    "    key={\"id\":1},\n",
    "    value={\"id\":1, \"name\":\"üë® Francesco\", \"pizza\":\"Margherita üçï\"},\n",
    "    partition=0\n",
    ")\n",
    "\n",
    "producer.produce(\n",
    "    \"pizzaPartitioned\",\n",
    "    key={\"id\":2},\n",
    "    value={\"id\":2, \"name\":\"üë© Adele\", \"pizza\":\"Hawaii üçï+üçç+ü•ì\"},\n",
    "    partition=1\n",
    ")\n",
    "```\n",
    "\n",
    "In `2-consume.ipynb` we saw that all the topics are all loaded. We're going to cre`ate two consumers that belong to the group `pizzaaioli`. `consumer_0` will consume messages in partition `0` and `consumer_1` consumes messages in partition `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from confluent_kafka import DeserializingConsumer, TopicPartition\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def json_serializer(msg, s_obj):\n",
    "    return json.loads(msg.decode('ascii'))\n",
    "\n",
    "KAFKA_SERVICE_URI = os.getenv(\"KAFKA_SERVICE_URI\")\n",
    "\n",
    "conf = {\n",
    "    'bootstrap.servers': KAFKA_SERVICE_URI,\n",
    "    'client.id': 'myclient',\n",
    "    'group.id': 'pizzaioli',\n",
    "    'security.protocol': 'SSL',\n",
    "    'ssl.ca.location': '../sslcerts/ca.pem',\n",
    "    'ssl.certificate.location': '../sslcerts/service.cert',\n",
    "    'ssl.key.location': '../sslcerts/service.key', \n",
    "    'value.deserializer': json_serializer,\n",
    "    'key.deserializer': json_serializer\n",
    "    }\n",
    "\n",
    "consumer_0 = DeserializingConsumer(conf)\n",
    "consumer_0.assign([TopicPartition(\"pizzaPartitioned\", 0)])\n",
    "consumer_1 = DeserializingConsumer(conf)\n",
    "consumer_1.assign([TopicPartition(\"pizzaPartitioned\", 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume messages to the `pizzaPartitioned` topic, partition 0\n",
    "\n",
    "Review and start the code block below. While the block is running. Use the **LAST** block in `3-produce-partitioned-topic.ipynb` to produced more partitioned samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the Producer in notebook 3\n",
      "Checking 0 \n",
      "----------\n",
      "0:28: {'id': 1}:{'id': 1, 'name': 'üë® Francesco', 'pizza': 'Margherita üçï'}\n",
      "\n",
      "\n",
      "Checking 1 \n",
      "----------\n",
      "1:18: {'id': 2}:{'id': 2, 'name': 'üë© Adele', 'pizza': 'Hawaii üçï+üçç+ü•ì'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import TopicPartition, KafkaException\n",
    "\n",
    "print(\"Run the Producer in notebook ...\")\n",
    "for consumer in [consumer_0, consumer_1]:\n",
    "    running = True\n",
    "    while running:\n",
    "        if (msg:=consumer.poll(timeout=1.0)) is None:\n",
    "            continue\n",
    "        elif msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "        else:\n",
    "            print(f\"Checking Partition {consumer.assignment()[0].partition} \\n\" + \"-\"*10)\n",
    "            print(f\"{msg.partition()}:{msg.offset()}: {msg.key()}:{msg.value()}\\n\\n\")\n",
    "            running = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
